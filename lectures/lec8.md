# ğŸ“Œ Lecture 8 â€” Monitoring with Prometheus: From Guessing to Measuring

## ğŸ“ Slide 1 â€“ ğŸš€ Welcome to Metrics Monitoring

* ğŸŒ **Logs tell you what happened** â€” but how much and how fast?
* ğŸ˜° Without metrics, capacity planning is guesswork
* ğŸ“Š **Prometheus** = the industry standard for metrics
* ğŸ¯ This lecture: master metrics collection, PromQL, and dashboards

```mermaid
flowchart LR
  App[ğŸ“¦ Application] -->|ğŸ“Š Metrics| Prometheus[ğŸ’¾ Prometheus]
  Prometheus --> Grafana[ğŸ“Š Grafana]
  Grafana --> Insight[ğŸ’¡ Insight]
```

---

## ğŸ“ Slide 2 â€“ ğŸ¯ What You Will Learn

* âœ… Understand metrics types and instrumentation
* âœ… Configure Prometheus for metrics collection
* âœ… Query metrics with PromQL
* âœ… Build effective monitoring dashboards

**ğŸ“ Learning Outcomes:**
| # | Outcome |
|---|---------|
| 1 | ğŸ§  Differentiate Counter, Gauge, Histogram |
| 2 | ğŸ” Configure Prometheus scrape targets |
| 3 | ğŸ› ï¸ Write PromQL queries for analysis |
| 4 | ğŸ—ºï¸ Design RED method dashboards |

---

## ğŸ“ Slide 3 â€“ ğŸ“‹ How This Lecture Works

* ğŸ“š **Concepts + Instrumentation** â€” hands-on focus
* ğŸ® **Real-world scenarios** â€” performance monitoring
* ğŸ“ **3 quiz checkpoints**: PRE / MID / POST
* ğŸ› ï¸ **Methods**: RED, USE, Four Golden Signals

**â±ï¸ Lecture Structure:**
```
Section 0: Introduction (now)     â†’ ğŸ“ PRE Quiz
Section 1: The Monitoring Problem
Section 2: Prometheus Fundamentals
Section 3: Application Instrumentation â†’ ğŸ“ MID Quiz
Section 4: PromQL & Dashboards
Section 5: Production Monitoring
Section 6: Reflection             â†’ ğŸ“ POST Quiz
```

---

## ğŸ“ Slide 4 â€“ â“ The Big Question

* ğŸ“Š **83%** of organizations can't predict performance issues
* â±ï¸ Average time to detect capacity problems: **too late**
* ğŸ’¥ Without metrics, you're **reactive, not proactive**

> ğŸ’¬ *"Is the server slow or is it just me?"* â€” Everyone, always

**ğŸ¤” Think about it:**
* How do you know if your app can handle more load?
* When did response times start degrading?
* How much headroom do you have?

---

## ğŸ“ Slide 5 â€“ ğŸ“ QUIZ â€” DEVOPS_L8_PRE

---

## ğŸ“ Slide 6 â€“ ğŸ”¥ Section 1: The Monitoring Problem

* ğŸ¤· **No metrics** = can't measure performance
* ğŸ“Š Users complain before you know there's a problem
* ğŸ” Can't identify bottlenecks
* ğŸ’¥ Result: **reactive firefighting**

```mermaid
flowchart LR
  Users[ğŸ‘¥ Users Complain] --> Support[ğŸ“ Support Ticket]
  Support --> Team[ğŸ‘¨â€ğŸ’» Team Investigates]
  Team --> Guess[ğŸ¤· Guesswork]
  Guess --> Hours[â±ï¸ Hours Later...]
```

---

## ğŸ“ Slide 7 â€“ ğŸ“Š Metrics vs Logs

```mermaid
flowchart TD
  subgraph ğŸ“‹ Logs
    L1[What happened?]
    L2[Detailed events]
    L3[High cardinality]
  end
  subgraph ğŸ“Š Metrics
    M1[How much/fast?]
    M2[Aggregated numbers]
    M3[Low cardinality]
  end
```

| ğŸ“‹ Aspect | ğŸ“Š Metrics | ğŸ“ Logs |
|-----------|----------|---------|
| ğŸ¯ Question | How much? | What happened? |
| ğŸ“ˆ Volume | Low | High |
| ğŸ’¾ Storage | Small | Large |
| ğŸ” Analysis | Trends, alerts | Debugging |
| â±ï¸ Retention | Long (months) | Short (days) |

> ğŸ”¥ **Use both**: Logs for debugging, metrics for monitoring

---

## ğŸ“ Slide 8 â€“ ğŸ˜± Alert Blindness

* ğŸš¨ No alerts = problems go unnoticed
* ğŸ“§ Too many alerts = alert fatigue
* ğŸ” Wrong thresholds = false positives
* ğŸ’€ On-call burnout

> âš ï¸ **Good metrics = actionable alerts**

```mermaid
flowchart LR
  NoMetrics[ğŸ™ˆ No Metrics] --> NoAlerts[ğŸ”‡ No Alerts]
  NoAlerts --> UserReports[ğŸ‘¥ Users Report]
  UserReports --> Scramble[ğŸ˜± Scramble]
```

---

## ğŸ“ Slide 9 â€“ ğŸ˜¨ Capacity Planning Without Metrics

* ğŸ“… "We need more servers" â€” but how many?
* ğŸ”® Crystal ball capacity planning
* ğŸ’° Over-provision (waste money) or under-provision (outages)
* ğŸ’€ No data to justify decisions

> âš ï¸ **Without metrics, capacity planning is gambling**

**ğŸ’¬ Discussion:** How does your team plan capacity?

---

## ğŸ“ Slide 10 â€“ ğŸ’¸ The Cost of Blind Monitoring

| ğŸ”¥ Problem | ğŸ’¥ Impact |
|------------|-----------|
| ğŸ¢ No baseline | Can't detect degradation |
| ğŸ“Š No trends | Can't predict growth |
| ğŸ‘‰ No attribution | Can't identify bottlenecks |
| ğŸ™ˆ No thresholds | Can't alert proactively |

**ğŸ“ˆ Real Numbers:**
* ğŸ¢ **Reactive incident detection**: Users report first (30+ min delay)
* ğŸš€ **Proactive with metrics**: Alert in seconds
* ğŸ’° **Cost of 30-minute delay**: $150,000+ (enterprise)

---

## ğŸ“ Slide 11 â€“ ğŸ’¡ Section 2: What Prometheus Is

* ğŸ“Š **Time-series database** for metrics
* ğŸ”„ **Pull-based** model â€” scrapes targets
* ğŸ“ˆ **PromQL** â€” powerful query language
* ğŸ¯ Industry standard for cloud-native monitoring

```mermaid
flowchart LR
  App1[ğŸ“¦ App /metrics] --> Prometheus[ğŸ’¾ Prometheus]
  App2[ğŸ“¦ Service /metrics] --> Prometheus
  Prometheus -->|â° Every 15s| Scrape[ğŸ”„ Pull Metrics]
```

**ğŸ“– Definition:**
> *Prometheus is an open-source monitoring system that collects metrics from targets by scraping HTTP endpoints, stores them in a time-series database, and provides a powerful query language (PromQL) for analysis.*

---

## ğŸ“ Slide 12 â€“ ğŸ”„ Pull vs Push Model

```mermaid
flowchart TD
  subgraph Pull (Prometheus)
    P1[ğŸ’¾ Prometheus] -->|ğŸ”„ Scrape| T1[ğŸ“¦ Target]
    P1 -->|ğŸ”„ Scrape| T2[ğŸ“¦ Target]
  end
  subgraph Push (StatsD)
    S1[ğŸ“¦ App] -->|ğŸ“¤ Push| D1[ğŸ’¾ Collector]
    S2[ğŸ“¦ App] -->|ğŸ“¤ Push| D1
  end
```

**ğŸ”„ Pull Benefits:**
* ğŸ” Prometheus controls the rate
* âœ… Know immediately if target is down (scrape fails)
* ğŸ¯ Apps don't need to know about monitoring
* ğŸ”§ Easy service discovery

---

## ğŸ“ Slide 13 â€“ ğŸ—ï¸ Prometheus Architecture

```mermaid
flowchart TD
  Targets[ğŸ“¦ Targets /metrics] --> Prometheus[ğŸ’¾ Prometheus TSDB]
  Prometheus --> AlertManager[ğŸš¨ AlertManager]
  Prometheus --> Grafana[ğŸ“Š Grafana]
  Prometheus --> API[ğŸ”— HTTP API]
  AlertManager --> Slack[ğŸ’¬ Slack]
  AlertManager --> PagerDuty[ğŸ“Ÿ PagerDuty]
```

| ğŸ§± Component | ğŸ¯ Purpose |
|-------------|----------|
| ğŸ’¾ **Prometheus** | Scrape, store, query |
| ğŸ“¦ **Targets** | Expose /metrics endpoint |
| ğŸš¨ **AlertManager** | Handle alerts |
| ğŸ“Š **Grafana** | Visualization |

---

## ğŸ“ Slide 14 â€“ ğŸ“Š Metric Types

```mermaid
flowchart LR
  Counter[ğŸ”¢ Counter] --> Always[Only goes UP]
  Gauge[ğŸ“Š Gauge] --> UpDown[Goes up AND down]
  Histogram[ğŸ“ˆ Histogram] --> Distribution[Value distribution]
```

| ğŸ“Š Type | ğŸ¯ Use For | ğŸ“ Example |
|---------|----------|---------|
| ğŸ”¢ **Counter** | Cumulative events | Total requests |
| ğŸ“Š **Gauge** | Current value | Temperature, memory |
| ğŸ“ˆ **Histogram** | Distribution | Request latency |
| ğŸ“Š **Summary** | Percentiles | Pre-calculated p95 |

---

## ğŸ“ Slide 15 â€“ ğŸ”¢ Counter Deep Dive

```python
from prometheus_client import Counter

# ğŸ”¢ Counter: Only goes up
http_requests_total = Counter(
    'http_requests_total',
    'Total HTTP requests',
    ['method', 'endpoint', 'status']
)

# Usage
http_requests_total.labels(method='GET', endpoint='/', status='200').inc()
```

**ğŸ“Š Query Patterns:**
```promql
# Total requests
http_requests_total

# Requests per second (rate over 5m)
rate(http_requests_total[5m])

# Requests per second by endpoint
sum by (endpoint) (rate(http_requests_total[5m]))
```

**âš ï¸ Counter Rule:** Use `rate()` to get per-second values

---

## ğŸ“ Slide 16 â€“ ğŸ® Section 3: Application Instrumentation

## ğŸ Python prometheus_client

```python
from prometheus_client import Counter, Gauge, Histogram, generate_latest
from flask import Flask, Response

app = Flask(__name__)

# ğŸ“Š Define metrics
requests = Counter('http_requests', 'Total requests', ['method', 'path'])
latency = Histogram('http_latency_seconds', 'Request latency', ['path'])
in_progress = Gauge('http_in_progress', 'Requests in progress')

@app.route('/metrics')
def metrics():
    return Response(generate_latest(), content_type='text/plain')
```

**ğŸ® Let's instrument an application.**

---

## ğŸ“ Slide 17 â€“ ğŸ“Š Histogram Deep Dive

```python
from prometheus_client import Histogram

# ğŸ“ˆ Histogram with buckets
request_latency = Histogram(
    'http_request_duration_seconds',
    'Request latency in seconds',
    ['method', 'endpoint'],
    buckets=[0.01, 0.05, 0.1, 0.5, 1.0, 5.0]  # ğŸª£ Custom buckets
)

# Usage
with request_latency.labels(method='GET', endpoint='/').time():
    # ... handle request ...
    pass
```

**ğŸ“Š Query Patterns:**
```promql
# 95th percentile latency
histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))

# Average latency
rate(http_request_duration_seconds_sum[5m]) / rate(http_request_duration_seconds_count[5m])
```

---

## ğŸ“ Slide 18 â€“ ğŸ“ˆ The RED Method

```mermaid
flowchart LR
  R[ğŸ”´ Rate] --> Requests[Requests per second]
  E[ğŸŸ¡ Errors] --> Failures[Error rate]
  D[ğŸ”µ Duration] --> Latency[Response time]
```

**ğŸ“Š RED Method for Request-Driven Services:**

| ğŸ“Š Metric | ğŸ¯ Question | ğŸ“ PromQL |
|-----------|----------|---------|
| ğŸ”´ **Rate** | How busy? | `rate(requests[5m])` |
| ğŸŸ¡ **Errors** | How often failing? | `rate(errors[5m])` |
| ğŸ”µ **Duration** | How slow? | `histogram_quantile(0.95, ...)` |

**ğŸ¯ If you monitor only 3 things, monitor these!**

---

## ğŸ“ Slide 19 â€“ ğŸ“ˆ The USE Method

```mermaid
flowchart LR
  U[ğŸ“Š Utilization] --> HowMuch[% resource busy]
  S[ğŸ“Š Saturation] --> Queuing[Extra work waiting]
  E[ğŸ“Š Errors] --> Failures[Error count]
```

**ğŸ“Š USE Method for Resources (CPU, Memory, Disk):**

| ğŸ“Š Metric | ğŸ¯ Example |
|-----------|----------|
| ğŸ“Š **Utilization** | CPU at 80% |
| ğŸ“Š **Saturation** | 10 requests queued |
| ğŸ“Š **Errors** | Disk I/O errors |

**ğŸ¯ USE for resources, RED for services**

---

## ğŸ“ Slide 20 â€“ âš™ï¸ Prometheus Configuration

```yaml
# prometheus/prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  - job_name: 'app'
    static_configs:
      - targets: ['app-python:8000']
    metrics_path: '/metrics'

  - job_name: 'loki'
    static_configs:
      - targets: ['loki:3100']
```

**ğŸ”‘ Key Settings:**
* â±ï¸ `scrape_interval`: How often to collect (15s default)
* ğŸ¯ `targets`: What to scrape
* ğŸ“ `metrics_path`: Where metrics are exposed

---

## ğŸ“ Slide 21 â€“ ğŸ¯ Scrape Targets

```mermaid
flowchart TD
  Prometheus[ğŸ’¾ Prometheus] -->|ğŸ”„ Scrape| App[ğŸ“¦ app:8000/metrics]
  Prometheus -->|ğŸ”„ Scrape| Loki[ğŸ“¦ loki:3100/metrics]
  Prometheus -->|ğŸ”„ Scrape| Grafana[ğŸ“¦ grafana:3000/metrics]
  Prometheus -->|ğŸ”„ Scrape| Self[ğŸ“¦ prometheus:9090/metrics]
```

**ğŸ“Š Verify Targets:**
```bash
# Check targets status
curl http://localhost:9090/api/v1/targets

# Web UI
http://localhost:9090/targets
```

**âœ… All targets should show `UP`**

---

## ğŸ“ Slide 22 â€“ ğŸ“Š /metrics Endpoint Format

```
# HELP http_requests_total Total HTTP requests
# TYPE http_requests_total counter
http_requests_total{method="GET",endpoint="/",status="200"} 1234
http_requests_total{method="GET",endpoint="/health",status="200"} 567
http_requests_total{method="POST",endpoint="/api",status="201"} 89

# HELP http_request_duration_seconds Request latency
# TYPE http_request_duration_seconds histogram
http_request_duration_seconds_bucket{le="0.01"} 100
http_request_duration_seconds_bucket{le="0.05"} 200
http_request_duration_seconds_bucket{le="0.1"} 250
http_request_duration_seconds_bucket{le="+Inf"} 300
http_request_duration_seconds_sum 45.67
http_request_duration_seconds_count 300
```

**ğŸ“Š Format:** `metric_name{labels} value`

---

## ğŸ“ Slide 23 â€“ ğŸ·ï¸ Labels Best Practices

```python
# âœ… Good: Low cardinality labels
http_requests.labels(method='GET', status='200', endpoint='/api')

# âŒ Bad: High cardinality (user IDs, request IDs)
http_requests.labels(user_id='12345')  # ğŸ’¥ Millions of time series!
```

**ğŸ·ï¸ Label Rules:**
* âœ… Use for: method, endpoint, status, service
* âŒ Avoid: user_id, request_id, session_id
* ğŸ“Š Target: < 1000 unique label combinations

**âš ï¸ High cardinality = memory explosion**

---

## ğŸ“ Slide 24 â€“ ğŸ” PromQL Basics

```promql
# Instant vector (current value)
http_requests_total

# Range vector (over time)
http_requests_total[5m]

# Rate (per-second)
rate(http_requests_total[5m])

# Sum by label
sum by (endpoint) (rate(http_requests_total[5m]))

# Filter by label
http_requests_total{status="500"}
```

**ğŸ”‘ Key Operators:**
* `rate()` â€” Per-second rate for counters
* `sum()` â€” Aggregate across series
* `by ()` â€” Group results
* `{}` â€” Filter by labels

---

## ğŸ“ Slide 25 â€“ ğŸ“ QUIZ â€” DEVOPS_L8_MID

---

## ğŸ“ Slide 26 â€“ ğŸ“Š Section 4: Building Dashboards

## ğŸ¨ Dashboard Design with RED

```mermaid
flowchart TD
  Row1[ğŸ” Row 1: Overview Stats]
  Row2[ğŸ“Š Row 2: Rate & Errors]
  Row3[â±ï¸ Row 3: Latency]
  Row4[ğŸ“‹ Row 4: Details]
  Row1 --> Row2 --> Row3 --> Row4
```

**ğŸ“Š Essential Panels:**
1. ğŸ“Š **Request Rate** â€” Requests per second
2. âŒ **Error Rate** â€” 5xx responses
3. â±ï¸ **Latency p95** â€” 95th percentile
4. ğŸ“ˆ **Latency Heatmap** â€” Distribution

---

## ğŸ“ Slide 27 â€“ ğŸ“Š PromQL Dashboard Queries

**1ï¸âƒ£ Request Rate (Time series)**
```promql
sum(rate(http_requests_total[5m])) by (endpoint)
```

**2ï¸âƒ£ Error Rate % (Time series)**
```promql
sum(rate(http_requests_total{status=~"5.."}[5m]))
  / sum(rate(http_requests_total[5m])) * 100
```

**3ï¸âƒ£ P95 Latency (Time series)**
```promql
histogram_quantile(0.95,
  sum(rate(http_request_duration_seconds_bucket[5m])) by (le))
```

**4ï¸âƒ£ Uptime (Stat)**
```promql
up{job="app"}
```

---

## ğŸ“ Slide 28 â€“ ğŸ“ˆ Heatmap for Latency

```promql
# Latency distribution over time
sum(rate(http_request_duration_seconds_bucket[1m])) by (le)
```

**ğŸ¨ Heatmap Benefits:**
* ğŸ“Š See latency distribution
* ğŸ” Spot outliers
* ğŸ“ˆ Track changes over time

```mermaid
flowchart LR
  Green[ğŸŸ¢ Fast: < 100ms] --> Yellow[ğŸŸ¡ OK: 100-500ms]
  Yellow --> Red[ğŸ”´ Slow: > 500ms]
```

---

## ğŸ“ Slide 29 â€“ ğŸ“Š Monitoring Metrics

| ğŸ“Š Metric | ğŸ“ Measures | ğŸ† Target |
|-----------|------------|---------|
| â±ï¸ **Scrape Success** | Targets reachable | 100% |
| ğŸ“Š **Series Count** | Time series | Stable |
| ğŸ’¾ **Storage Size** | Disk usage | Predictable |
| ğŸ” **Query Latency** | PromQL speed | < 1s |

> ğŸ“š Monitor your monitoring!

**ğŸ¤” Question:** What happens if Prometheus goes down?

---

## ğŸ“ Slide 30 â€“ ğŸŒŠ From Guessing to Measuring

```mermaid
flowchart LR
  subgraph ğŸ˜± Guessing
    NoData[ğŸ¤· No Data]
    Reactive[ğŸ”¥ Reactive]
    Slow[â±ï¸ Slow Detection]
  end
  subgraph ğŸ“Š Measuring
    Metrics[ğŸ“ˆ Real Metrics]
    Proactive[âš¡ Proactive]
    Fast[ğŸš€ Instant Detection]
  end
  Guessing -->|ğŸš€ Prometheus| Measuring
```

**ğŸ¯ Monitoring State:**
* âš¡ Detect issues before users
* ğŸ“Š Data-driven capacity planning
* ğŸ“ˆ Trend analysis and predictions

---

## ğŸ“ Slide 31 â€“ ğŸ¢ Section 5: Production Monitoring

## ğŸ“… A Day with Prometheus

**â˜€ï¸ Morning:**
* ğŸ“Š Check Grafana â€” all green âœ…
* ğŸ“ˆ Review overnight trends
* ğŸ” No anomalies detected

**ğŸŒ¤ï¸ Afternoon:**
* ğŸš¨ Alert: Latency p95 > 500ms
* ğŸ“Š Dashboard shows spike at 2pm
* ğŸ” PromQL: `histogram_quantile(0.95, ...)`
* ğŸ”§ Found: Database slow query
* â±ï¸ **5 minutes** to identify

**ğŸŒ™ Evening:**
* ğŸ“Š Review daily trends
* ğŸ“ˆ Plan tomorrow's capacity
* ğŸ  Go home with confidence

---

## ğŸ“ Slide 32 â€“ ğŸ‘¥ Team Monitoring Workflow

| ğŸ‘¤ Role | ğŸ¯ Monitoring Responsibility |
|---------|----------------------|
| ğŸ‘¨â€ğŸ’» **Developer** | Add metrics to code |
| ğŸ”§ **DevOps** | Maintain Prometheus |
| ğŸ›¡ï¸ **SRE** | Design dashboards & alerts |
| ğŸ“Š **On-call** | Respond to alerts |

**ğŸ”— Alert Flow:**
```mermaid
flowchart LR
  Prometheus[ğŸ’¾ Prometheus] -->|ğŸš¨ Alert| AlertManager[ğŸ“¬ AlertManager]
  AlertManager --> Slack[ğŸ’¬ Slack]
  AlertManager --> PagerDuty[ğŸ“Ÿ PagerDuty]
  PagerDuty --> OnCall[ğŸ‘¤ On-call]
```

---

## ğŸ“ Slide 33 â€“ ğŸ” Production Considerations

```yaml
# Prometheus with retention
command:
  - '--config.file=/etc/prometheus/prometheus.yml'
  - '--storage.tsdb.retention.time=15d'
  - '--storage.tsdb.retention.size=10GB'

deploy:
  resources:
    limits:
      memory: 1G
      cpus: '1.0'

healthcheck:
  test: ["CMD", "wget", "-q", "--spider", "http://localhost:9090/-/healthy"]
  interval: 10s
  timeout: 5s
  retries: 5
```

**ğŸ›¡ï¸ Production Checklist:**
* ğŸ’¾ Persistent storage configured
* ğŸ—“ï¸ Retention policy set
* ğŸ“Š Resource limits defined
* ğŸ¥ Health checks enabled

---

## ğŸ“ Slide 34 â€“ ğŸ“ˆ Career Path: Monitoring Skills

```mermaid
flowchart LR
  Junior[ğŸŒ± Junior: Basic metrics] --> Mid[ğŸ’¼ Mid: PromQL & dashboards]
  Mid --> Senior[â­ Senior: Full observability]
  Senior --> Principal[ğŸ† Principal: SRE practices]
```

**ğŸ› ï¸ Skills to Build:**
* ğŸ“Š Application instrumentation
* ğŸ” PromQL fluency
* ğŸ“ˆ Dashboard design
* ğŸš¨ Alert engineering
* ğŸ“Š SLO/SLI definition

---

## ğŸ“ Slide 35 â€“ ğŸŒ Real Company Examples

**ğŸ¢ Prometheus at Scale:**
* â˜ï¸ **SoundCloud**: Created Prometheus (2012)
* ğŸ” **Google**: Inspired Prometheus (Borgmon)
* ğŸ¬ **Netflix**: Millions of time series

**â˜ï¸ Modern Practices:**
* ğŸ“¦ **Spotify**: Custom Prometheus federation
* ğŸ¦ **Stripe**: Fine-grained latency tracking
* ğŸ® **Riot Games**: Real-time game metrics

**ğŸ“Š Stats:**
* ğŸŒ **#1** cloud-native monitoring tool
* ğŸ“¦ **CNCF graduated** project
* ğŸ¢ Adopted by **70%+** of K8s users

---

## ğŸ“ Slide 36 â€“ ğŸ¯ Section 6: Reflection

## ğŸ“ Key Takeaways

1. ğŸ“Š **Metrics complement logs** â€” different purposes
2. ğŸ”¢ **Counter, Gauge, Histogram** â€” choose wisely
3. ğŸ”´ **RED method** for services (Rate, Errors, Duration)
4. ğŸ·ï¸ **Labels** â€” keep cardinality low
5. ğŸ“ˆ **PromQL** is powerful â€” learn it well

> ğŸ’¡ If you can't measure it, you can't improve it.

---

## ğŸ“ Slide 37 â€“ ğŸ§  The Mindset Shift

| ğŸ˜° Old Mindset | ğŸ“Š Metrics Mindset |
|---------------|------------------|
| ğŸ™… "Seems fine" | ğŸ“Š "Data shows it's fine" |
| ğŸš« "Users will tell us" | ğŸš¨ "Alerts tell us first" |
| ğŸ‘‰ "We need more servers" | ğŸ“ˆ "Data shows we need 3 more" |
| ğŸ˜¨ "Deploy and hope" | ğŸ“Š "Deploy and measure" |
| ğŸ’» "Performance is subjective" | ğŸ”¢ "p95 is 250ms" |

> â“ Which mindset describes your team?

---

## ğŸ“ Slide 38 â€“ âœ… Your Progress

## ğŸ“ What You Now Understand

* âœ… Metrics types and when to use each
* âœ… Prometheus architecture and configuration
* âœ… Application instrumentation patterns
* âœ… PromQL query syntax
* âœ… Dashboard design with RED method

> ğŸš€ **You're ready for Lab 8: Prometheus Monitoring**

---

## ğŸ“ Slide 39 â€“ ğŸ“ QUIZ â€” DEVOPS_L8_POST

---

## ğŸ“ Slide 40 â€“ ğŸš€ What Comes Next

## ğŸ“š Next Lecture: Kubernetes Fundamentals

* â˜¸ï¸ Container orchestration
* ğŸ“¦ Deployments and Services
* ğŸ”„ Scaling and self-healing
* ğŸ’» Hands-on: Deploying to Kubernetes

**ğŸ‰ Your monitoring journey continues.**

> ğŸ“Š From guessing to measuring â€” one metric at a time.

```mermaid
flowchart LR
  You[ğŸ‘¤ You] --> Metrics[ğŸ“Š Metrics Skills]
  Metrics --> DataDriven[ğŸ“ˆ Data-Driven Ops]
  DataDriven --> Career[ğŸš€ Career Growth]
```

**ğŸ‘‹ See you in the next lecture!**

---

## ğŸ“š Resources & Further Reading

**ğŸ“• Books:**
* ğŸ“– *Prometheus: Up & Running* â€” Brian Brazil
* ğŸ“– *Site Reliability Engineering* â€” Google
* ğŸ“– *The Art of Monitoring* â€” James Turnbull

**ğŸ”— Links:**
* ğŸŒ [Prometheus Documentation](https://prometheus.io/docs/)
* ğŸŒ [PromQL Basics](https://prometheus.io/docs/prometheus/latest/querying/basics/)
* ğŸŒ [RED Method](https://grafana.com/blog/2018/08/02/the-red-method-how-to-instrument-your-services/)

---
